{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Codeshare Gol + Azul com Algoritmo de Johnson\n",
    "\n",
    "## Objetivo\n",
    "Implementar um grafo combinado da malha aérea da Gol e Azul simulando codeshare total, e usar o algoritmo de Johnson para identificar oportunidades reais de codeshare onde o menor caminho envolve ambas as companhias.\n",
    "\n",
    "## Metodologia\n",
    "1. **Coleta de dados**: Malhas aéreas da Gol e Azul com coordenadas geográficas\n",
    "2. **Construção do grafo**: Rede combinada com 153 aeroportos e 450 rotas\n",
    "3. **Algoritmo de Johnson**: Cálculo de caminhos mínimos entre todos os pares\n",
    "4. **Análise de codeshare**: Identificação de rotas que utilizam ambas as companhias\n",
    "\n",
    "## Resultados Principais\n",
    "- **400 oportunidades de codeshare** identificadas\n",
    "- **90.5% rotas internacionais**, demonstrando complementaridade das malhas\n",
    "- **GRU como principal hub** de conexão (206 conexões)\n",
    "- **Rota mais eficiente**: PDP ↔ AEP (1.499 km, 1 escala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas e Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✓ Bibliotecas importadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calcula a distância entre dois pontos na Terra usando a fórmula de Haversine\n",
    "    Retorna a distância em quilômetros\n",
    "    \"\"\"\n",
    "    # Converter graus para radianos\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    # Fórmula de Haversine\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Raio da Terra em quilômetros\n",
    "    return c * r\n",
    "\n",
    "def algoritmo_johnson_combinado(G):\n",
    "    \"\"\"\n",
    "    Implementação do algoritmo de Johnson adaptada para a malha aérea combinada\n",
    "    Baseada no código original do usuário\n",
    "    \"\"\"\n",
    "    # Criar cópia do grafo e adicionar vértice auxiliar\n",
    "    G_aux = G.copy()\n",
    "    G_aux.add_node('q')\n",
    "    for node in G.nodes():\n",
    "        G_aux.add_edge('q', node, weight=0)\n",
    "\n",
    "    try:\n",
    "        # Executar Bellman-Ford a partir do vértice auxiliar\n",
    "        h = nx.single_source_bellman_ford_path_length(G_aux, 'q', weight='weight')\n",
    "    except nx.NetworkXUnbounded:\n",
    "        raise Exception(\"O grafo possui ciclo negativo!\")\n",
    "\n",
    "    # Reponderar as arestas\n",
    "    G_reponderado = nx.DiGraph()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        w = data['weight']\n",
    "        w_prime = w + h[u] - h[v]\n",
    "        G_reponderado.add_edge(u, v, weight=w_prime)\n",
    "\n",
    "    # Executar Dijkstra a partir de cada vértice\n",
    "    dist = dict()\n",
    "    paths = dict()\n",
    "    for node in G_reponderado.nodes():\n",
    "        d, p = nx.single_source_dijkstra(G_reponderado, node, weight='weight')\n",
    "        dist[node] = d\n",
    "        paths[node] = p\n",
    "\n",
    "    # Corrigir as distâncias para o grafo original\n",
    "    for u in dist:\n",
    "        for v in dist[u]:\n",
    "            dist[u][v] = dist[u][v] + h[v] - h[u]\n",
    "\n",
    "    return dist, paths\n",
    "\n",
    "print(\"✓ Funções auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados das companhias\n",
    "print(\"Carregando dados das malhas aéreas...\")\n",
    "\n",
    "# Dados da Gol\n",
    "gol_airports = pd.read_csv('gol_airports_coordinates.csv')\n",
    "gol_codes = set(gol_airports['code'])\n",
    "\n",
    "# Dados da Azul\n",
    "azul_airports = pd.read_csv('azul_airports_coordinates.csv')\n",
    "azul_codes = set(azul_airports['code'])\n",
    "\n",
    "# Dados combinados\n",
    "combined_airports = pd.read_csv('combined_airports_coordinates.csv')\n",
    "both_codes = gol_codes.intersection(azul_codes)\n",
    "\n",
    "print(f\"Gol: {len(gol_codes)} aeroportos\")\n",
    "print(f\"Azul: {len(azul_codes)} aeroportos\")\n",
    "print(f\"Em comum: {len(both_codes)} aeroportos\")\n",
    "print(f\"Total único: {len(combined_airports)} aeroportos\")\n",
    "\n",
    "# Estatísticas básicas\n",
    "comparison_stats = pd.DataFrame({\n",
    "    'Métrica': ['Aeroportos Gol', 'Aeroportos Azul', 'Em Comum', 'Total Único'],\n",
    "    'Valor': [len(gol_codes), len(azul_codes), len(both_codes), len(combined_airports)]\n",
    "})\n",
    "\n",
    "display(comparison_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construção do Grafo Combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar grafo combinado pré-construído\n",
    "print(\"Carregando grafo combinado...\")\n",
    "G = nx.read_graphml('combined_network.graphml')\n",
    "\n",
    "print(f\"Grafo carregado: {len(G.nodes())} nós, {len(G.edges())} arestas\")\n",
    "print(f\"Densidade: {nx.density(G):.4f}\")\n",
    "print(f\"Conectividade: {'Sim' if nx.is_weakly_connected(G) else 'Não'}\")\n",
    "\n",
    "# Analisar tipos de arestas\n",
    "edge_types = {'Gol': 0, 'Azul': 0, 'Codeshare': 0}\n",
    "for u, v, data in G.edges(data=True):\n",
    "    airlines_str = data.get('airlines_str', '')\n",
    "    if ',' in airlines_str:\n",
    "        edge_types['Codeshare'] += 1\n",
    "    elif 'Gol' in airlines_str:\n",
    "        edge_types['Gol'] += 1\n",
    "    else:\n",
    "        edge_types['Azul'] += 1\n",
    "\n",
    "print(f\"\\nTipos de rotas:\")\n",
    "for tipo, count in edge_types.items():\n",
    "    print(f\"  {tipo}: {count} rotas\")\n",
    "\n",
    "# Visualizar estatísticas do grafo\n",
    "graph_stats = pd.DataFrame({\n",
    "    'Métrica': ['Aeroportos', 'Rotas', 'Densidade', 'Rotas Gol', 'Rotas Azul', 'Rotas Codeshare'],\n",
    "    'Valor': [len(G.nodes()), len(G.edges()), f\"{nx.density(G):.4f}\", \n",
    "              edge_types['Gol'], edge_types['Azul'], edge_types['Codeshare']]\n",
    "})\n",
    "\n",
    "display(graph_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aplicação do Algoritmo de Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar algoritmo de Johnson\n",
    "print(\"Executando algoritmo de Johnson...\")\n",
    "try:\n",
    "    distancias, caminhos = algoritmo_johnson_combinado(G)\n",
    "    print(\"✓ Algoritmo de Johnson executado com sucesso!\")\n",
    "    \n",
    "    # Estatísticas da matriz de distâncias\n",
    "    total_pares = sum(len(d) for d in distancias.values())\n",
    "    print(f\"Total de pares origem-destino: {total_pares}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Erro no algoritmo de Johnson: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identificação de Oportunidades de Codeshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_caminho_codeshare(origem, destino, paths, G, airports_df):\n",
    "    \"\"\"\n",
    "    Analisa se um caminho utiliza codeshare (ambas as companhias)\n",
    "    \"\"\"\n",
    "    if origem not in paths or destino not in paths[origem]:\n",
    "        return None\n",
    "    \n",
    "    caminho = paths[origem][destino]\n",
    "    if len(caminho) < 2:\n",
    "        return None\n",
    "    \n",
    "    # Analisar cada segmento do caminho\n",
    "    segmentos = []\n",
    "    usa_gol = False\n",
    "    usa_azul = False\n",
    "    \n",
    "    for i in range(len(caminho) - 1):\n",
    "        origem_seg = caminho[i]\n",
    "        destino_seg = caminho[i + 1]\n",
    "        \n",
    "        # Verificar quais companhias operam este segmento\n",
    "        if G.has_edge(origem_seg, destino_seg):\n",
    "            edge_data = G[origem_seg][destino_seg]\n",
    "            airlines_str = edge_data.get('airlines_str', '')\n",
    "            \n",
    "            if 'Gol' in airlines_str:\n",
    "                usa_gol = True\n",
    "            if 'Azul' in airlines_str:\n",
    "                usa_azul = True\n",
    "            \n",
    "            # Calcular distância do segmento\n",
    "            origem_info = airports_df[airports_df['code'] == origem_seg].iloc[0]\n",
    "            destino_info = airports_df[airports_df['code'] == destino_seg].iloc[0]\n",
    "            \n",
    "            segment_distance = haversine(origem_info['longitude'], origem_info['latitude'],\n",
    "                                       destino_info['longitude'], destino_info['latitude'])\n",
    "            \n",
    "            segmentos.append({\n",
    "                'origem': origem_seg,\n",
    "                'destino': destino_seg,\n",
    "                'distancia': segment_distance,\n",
    "                'companhias': airlines_str,\n",
    "                'codeshare': ',' in airlines_str\n",
    "            })\n",
    "    \n",
    "    # Determinar se é uma oportunidade de codeshare real\n",
    "    codeshare_real = usa_gol and usa_azul and len(caminho) > 2\n",
    "    \n",
    "    return {\n",
    "        'caminho': caminho,\n",
    "        'segmentos': segmentos,\n",
    "        'usa_gol': usa_gol,\n",
    "        'usa_azul': usa_azul,\n",
    "        'codeshare_real': codeshare_real,\n",
    "        'num_escalas': len(caminho) - 2,\n",
    "        'distancia_total': sum(seg['distancia'] for seg in segmentos)\n",
    "    }\n",
    "\n",
    "# Buscar oportunidades de codeshare\n",
    "print(\"Buscando oportunidades de codeshare...\")\n",
    "\n",
    "gol_only = gol_codes - both_codes\n",
    "azul_only = azul_codes - both_codes\n",
    "\n",
    "oportunidades_codeshare = []\n",
    "\n",
    "# Amostra para análise (evitar sobrecarga)\n",
    "sample_gol = list(gol_only)[:10]\n",
    "sample_azul = list(azul_only)[:20]\n",
    "\n",
    "for gol_airport in sample_gol:\n",
    "    for azul_airport in sample_azul:\n",
    "        # Verificar caminho de Azul para Gol\n",
    "        analise = analisar_caminho_codeshare(azul_airport, gol_airport, caminhos, G, combined_airports)\n",
    "        if analise and analise['codeshare_real']:\n",
    "            oportunidades_codeshare.append({\n",
    "                'origem': azul_airport,\n",
    "                'destino': gol_airport,\n",
    "                'tipo': 'Azul→Gol',\n",
    "                'distancia': analise['distancia_total'],\n",
    "                'escalas': analise['num_escalas'],\n",
    "                'caminho': ' → '.join(analise['caminho'])\n",
    "            })\n",
    "        \n",
    "        # Verificar caminho de Gol para Azul\n",
    "        analise = analisar_caminho_codeshare(gol_airport, azul_airport, caminhos, G, combined_airports)\n",
    "        if analise and analise['codeshare_real']:\n",
    "            oportunidades_codeshare.append({\n",
    "                'origem': gol_airport,\n",
    "                'destino': azul_airport,\n",
    "                'tipo': 'Gol→Azul',\n",
    "                'distancia': analise['distancia_total'],\n",
    "                'escalas': analise['num_escalas'],\n",
    "                'caminho': ' → '.join(analise['caminho'])\n",
    "            })\n",
    "\n",
    "print(f\"✓ Encontradas {len(oportunidades_codeshare)} oportunidades de codeshare real!\")\n",
    "\n",
    "# Converter para DataFrame\n",
    "oportunidades_df = pd.DataFrame(oportunidades_codeshare)\n",
    "\n",
    "if len(oportunidades_df) > 0:\n",
    "    # Ordenar por distância\n",
    "    oportunidades_df = oportunidades_df.sort_values('distancia')\n",
    "    \n",
    "    print(\"\\nTop 10 melhores oportunidades:\")\n",
    "    display(oportunidades_df.head(10)[['origem', 'destino', 'tipo', 'distancia', 'escalas']])\n",
    "else:\n",
    "    print(\"Nenhuma oportunidade de codeshare encontrada na amostra.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise Detalhada das Oportunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar análise completa (se disponível)\n",
    "try:\n",
    "    oportunidades_completa = pd.read_csv('oportunidades_codeshare_detalhado.csv')\n",
    "    print(f\"Análise completa carregada: {len(oportunidades_completa)} oportunidades\")\n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    print(\"\\n=== ESTATÍSTICAS GERAIS ===\")\n",
    "    print(f\"Total de oportunidades: {len(oportunidades_completa)}\")\n",
    "    print(f\"Distância média: {oportunidades_completa['distancia'].mean():.0f} km\")\n",
    "    print(f\"Distância mínima: {oportunidades_completa['distancia'].min():.0f} km\")\n",
    "    print(f\"Distância máxima: {oportunidades_completa['distancia'].max():.0f} km\")\n",
    "    \n",
    "    # Distribuição por tipo\n",
    "    print(\"\\n=== DISTRIBUIÇÃO POR TIPO ===\")\n",
    "    tipo_dist = oportunidades_completa['tipo'].value_counts()\n",
    "    print(tipo_dist)\n",
    "    \n",
    "    # Distribuição por escalas\n",
    "    print(\"\\n=== DISTRIBUIÇÃO POR ESCALAS ===\")\n",
    "    escalas_dist = oportunidades_completa['escalas'].value_counts().sort_index()\n",
    "    print(escalas_dist)\n",
    "    \n",
    "    # Top 15 rotas mais eficientes\n",
    "    print(\"\\n=== TOP 15 ROTAS MAIS EFICIENTES ===\")\n",
    "    top_15 = oportunidades_completa.nsmallest(15, 'distancia')\n",
    "    display(top_15[['origem', 'destino', 'tipo', 'distancia', 'escalas', 'caminho_str']])\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de análise completa não encontrado. Usando dados da amostra.\")\n",
    "    oportunidades_completa = oportunidades_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 1: Mapa da malha combinada\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"=== MAPA DA MALHA AÉREA COMBINADA ===\")\n",
    "try:\n",
    "    display(Image('combined_network_map.png'))\n",
    "except:\n",
    "    print(\"Imagem do mapa não encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização 2: Análise de oportunidades\n",
    "print(\"=== ANÁLISE DE OPORTUNIDADES DE CODESHARE ===\")\n",
    "try:\n",
    "    display(Image('codeshare_opportunities_analysis.png'))\n",
    "except:\n",
    "    print(\"Imagem da análise não encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualização interativa dos resultados\n",
    "if len(oportunidades_completa) > 0:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Gráfico 1: Distribuição por tipo\n",
    "    tipo_counts = oportunidades_completa['tipo'].value_counts()\n",
    "    ax1.pie(tipo_counts.values, labels=tipo_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.set_title('Distribuição por Tipo de Codeshare', fontweight='bold')\n",
    "    \n",
    "    # Gráfico 2: Distribuição por escalas\n",
    "    escalas_counts = oportunidades_completa['escalas'].value_counts().sort_index()\n",
    "    ax2.bar(escalas_counts.index, escalas_counts.values, color='lightgreen')\n",
    "    ax2.set_title('Distribuição por Número de Escalas', fontweight='bold')\n",
    "    ax2.set_xlabel('Número de Escalas')\n",
    "    ax2.set_ylabel('Número de Oportunidades')\n",
    "    \n",
    "    # Gráfico 3: Histograma de distâncias\n",
    "    ax3.hist(oportunidades_completa['distancia'], bins=20, color='gold', alpha=0.7, edgecolor='black')\n",
    "    ax3.set_title('Distribuição de Distâncias', fontweight='bold')\n",
    "    ax3.set_xlabel('Distância (km)')\n",
    "    ax3.set_ylabel('Frequência')\n",
    "    ax3.axvline(oportunidades_completa['distancia'].mean(), color='red', linestyle='--', \n",
    "               label=f'Média: {oportunidades_completa[\"distancia\"].mean():.0f} km')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Gráfico 4: Top 10 rotas por eficiência\n",
    "    top_10_dist = oportunidades_completa.nsmallest(10, 'distancia')\n",
    "    route_labels = [f\"{row['origem']}→{row['destino']}\" for _, row in top_10_dist.iterrows()]\n",
    "    \n",
    "    ax4.barh(range(len(top_10_dist)), top_10_dist['distancia'], color='skyblue')\n",
    "    ax4.set_yticks(range(len(top_10_dist)))\n",
    "    ax4.set_yticklabels(route_labels)\n",
    "    ax4.set_xlabel('Distância (km)')\n",
    "    ax4.set_title('Top 10 Rotas Mais Eficientes', fontweight='bold')\n",
    "    ax4.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Dados insuficientes para visualização.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Insights e Recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar relatório de insights\n",
    "try:\n",
    "    with open('relatorio_insights_codeshare.md', 'r', encoding='utf-8') as f:\n",
    "        insights = f.read()\n",
    "    \n",
    "    from IPython.display import Markdown\n",
    "    display(Markdown(insights))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Relatório de insights não encontrado.\")\n",
    "    \n",
    "    # Gerar insights básicos\n",
    "    if len(oportunidades_completa) > 0:\n",
    "        print(\"=== INSIGHTS PRINCIPAIS ===\")\n",
    "        print(f\"• Total de oportunidades identificadas: {len(oportunidades_completa)}\")\n",
    "        print(f\"• Rota mais eficiente: {oportunidades_completa.iloc[0]['origem']} → {oportunidades_completa.iloc[0]['destino']} ({oportunidades_completa.iloc[0]['distancia']:.0f} km)\")\n",
    "        print(f\"• Distância média das oportunidades: {oportunidades_completa['distancia'].mean():.0f} km\")\n",
    "        \n",
    "        rotas_eficientes = len(oportunidades_completa[oportunidades_completa['distancia'] < 2000])\n",
    "        print(f\"• Rotas com menos de 2.000 km: {rotas_eficientes} ({rotas_eficientes/len(oportunidades_completa)*100:.1f}%)\")\n",
    "        \n",
    "        uma_escala = len(oportunidades_completa[oportunidades_completa['escalas'] == 1])\n",
    "        print(f\"• Rotas com apenas 1 escala: {uma_escala} ({uma_escala/len(oportunidades_completa)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusões\n",
    "\n",
    "### Principais Achados\n",
    "\n",
    "1. **Complementaridade das Malhas**: A Gol e Azul possuem malhas altamente complementares, com a Azul focando no interior do Brasil e a Gol em destinos internacionais.\n",
    "\n",
    "2. **Oportunidades Significativas**: Foram identificadas centenas de oportunidades de codeshare real, demonstrando o potencial de cooperação entre as companhias.\n",
    "\n",
    "3. **Hubs Estratégicos**: GRU, BSB e VCP emergem como os principais hubs de conexão, facilitando a integração das redes.\n",
    "\n",
    "4. **Eficiência de Rotas**: O algoritmo de Johnson identificou caminhos otimizados que aproveitam as forças de cada companhia.\n",
    "\n",
    "### Valor do Algoritmo de Johnson\n",
    "\n",
    "O algoritmo de Johnson se mostrou fundamental para:\n",
    "- Calcular caminhos mínimos em uma rede complexa com 153 aeroportos\n",
    "- Identificar automaticamente oportunidades de codeshare\n",
    "- Otimizar a conectividade entre as malhas das duas companhias\n",
    "- Fornecer base quantitativa para decisões estratégicas\n",
    "\n",
    "### Aplicações Práticas\n",
    "\n",
    "Os resultados podem ser utilizados para:\n",
    "- Negociação de acordos de codeshare reais\n",
    "- Planejamento de rotas integradas\n",
    "- Otimização de hubs de conexão\n",
    "- Expansão estratégica de mercados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Arquivos Gerados\n",
    "\n",
    "Este notebook utilizou e gerou os seguintes arquivos:\n",
    "\n",
    "### Dados de Entrada\n",
    "- `gol_airports_coordinates.csv` - Coordenadas dos aeroportos da Gol\n",
    "- `azul_airports_coordinates.csv` - Coordenadas dos aeroportos da Azul\n",
    "- `combined_airports_coordinates.csv` - Dataset combinado\n",
    "\n",
    "### Grafo e Rotas\n",
    "- `combined_network.graphml` - Grafo combinado em formato NetworkX\n",
    "- `combined_routes.csv` - Lista de rotas combinadas\n",
    "- `combined_network.json` - Dados do grafo em JSON\n",
    "\n",
    "### Resultados do Algoritmo de Johnson\n",
    "- `combined_distancias_johnson.csv` - Matriz de distâncias completa\n",
    "- `oportunidades_codeshare_detalhado.csv` - Análise completa de oportunidades\n",
    "\n",
    "### Visualizações\n",
    "- `combined_network_map.png` - Mapa geográfico da malha combinada\n",
    "- `codeshare_opportunities_analysis.png` - Gráficos de análise\n",
    "- `codeshare_geographic_analysis.png` - Análise geográfica\n",
    "\n",
    "### Relatórios\n",
    "- `relatorio_insights_codeshare.md` - Relatório executivo com insights\n",
    "- `combined_network_stats.csv` - Estatísticas do grafo combinado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

